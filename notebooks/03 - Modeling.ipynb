{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b5aea22",
   "metadata": {},
   "source": [
    "# Notebook 03: Modeling\n",
    "#### Purpose:\n",
    "The purpose of this notebook is to train a model to semantically segment aerial cityscape imagery.\n",
    "\n",
    "#### Data:\n",
    "The training data comes from the Varied Drone Dataset (VDD) and the Semantic Drone Dataset (SDD).\n",
    "\n",
    "#### Process:\n",
    "The modeling process that takes place is as follows:\n",
    "1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6871cd",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8c29cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from keras.utils import to_categorical, normalize\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Conv2DTranspose, Dropout\n",
    "from keras.callbacks import Callback, CSVLogger, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b787385",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe175fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_data(folder, extension, image_shape):\n",
    "    \"\"\"\n",
    "    Description\n",
    "    -----------\n",
    "    Loads images from folder into a single array.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    folder : str\n",
    "        the folder path (including trailing /).\n",
    "    extension : str\n",
    "        the file extension (i.g. .jpeg, .bmp).\n",
    "    image_shape : tuple of int\n",
    "        image height by image width in pixels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    image_list : numpy array\n",
    "        loaded images stored in a numpy array.\n",
    "    \"\"\"\n",
    "    image_list = []\n",
    "    for directory_path in glob.glob(folder):\n",
    "        for img_path in glob.glob(os.path.join(directory_path, \"*\" + extension)):\n",
    "            img = cv2.imread(img_path, 0)  #being read as grayscale even though RGB\n",
    "            img = cv2.resize(img, image_shape, interpolation=cv2.INTER_NEAREST)  # nearest neighbor interpolation to prevent creation of new mask values\n",
    "            image_list.append(img)\n",
    "           \n",
    "    #Convert list to array for machine learning processing        \n",
    "    return np.array(image_list)\n",
    "\n",
    "\n",
    "def load_image_and_mask_data(image_folder, image_extension, mask_folder, mask_extension, image_shape):\n",
    "    #Load and resize train images and masks\n",
    "    images = get_image_data(image_folder, image_extension, image_shape)\n",
    "    masks = get_image_data(mask_folder, mask_extension, image_shape)\n",
    "    \n",
    "    #Encode mask labels (enforces 0-indexed labeling)\n",
    "    labelencoder = LabelEncoder()\n",
    "    n, h, w = masks.shape\n",
    "    masks_1_dim = masks.reshape(-1,1).ravel()\n",
    "    masks_1_dim_encoded = labelencoder.fit_transform(masks_1_dim)\n",
    "    masks_encoded = masks_1_dim_encoded.reshape(n, h, w)\n",
    "    \n",
    "    #Expand image dimensions and normalize\n",
    "    images_input = np.expand_dims(images, axis=3)  #(image, y, x, new_dimension)\n",
    "    images_input = normalize(images_input, axis=1)  #normalize each image\n",
    "    masks_expanded = np.expand_dims(masks_encoded, axis=3)  #(image, y, x, new_dimension)\n",
    "    \n",
    "    #Info\n",
    "    class_values = np.unique(masks_expanded)\n",
    "    n_classes = len(class_values)\n",
    "    print(\"Class labels in the dataset are ... \", class_values)\n",
    "    print(\"Number of classes in the dataset is ... \", n_classes)\n",
    "    \n",
    "    #One-hot encode mask classes\n",
    "    masks_input = to_categorical(masks_expanded, num_classes=n_classes)\n",
    "    \n",
    "    #Calculate balanced class weights\n",
    "    class_weights = class_weight.compute_class_weight(class_weight='balanced',\n",
    "                                                     classes=class_values,\n",
    "                                                     y=masks_1_dim_encoded)\n",
    "    class_weights_dict = {}\n",
    "    for ind, c in enumerate(np.unique(masks_1_dim_encoded)):\n",
    "        class_weights_dict[c] = class_weights[c]\n",
    "    print(\"Class weights dictionary looks like ...:\", class_weights_dict)\n",
    "    \n",
    "    return images_input, masks_input, n_classes, class_weights_dict\n",
    "\n",
    "\n",
    "def get_fold_indices(n_samples, n_folds):\n",
    "    \"\"\"\n",
    "    Description\n",
    "    -----------\n",
    "    Splits n_samples indices into n_folds folds for cross-validation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_samples : int\n",
    "        number of images in the training set to be used in the cross-validation.\n",
    "    n_folds : int\n",
    "        number of folds to split the training data into for cross-validation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    indices_by_fold : dict\n",
    "        dictionary of image indices split into `n_folds` folds (each fold gets its own key).\n",
    "    \"\"\"\n",
    "    x = n_samples // n_folds\n",
    "    \n",
    "    indices_by_fold = {}\n",
    "    \n",
    "    for n in range(n_folds):\n",
    "        fold_n = [i for i in range(x*n, x*n+x)]\n",
    "        \n",
    "        if n == (n_folds-1):\n",
    "            fold_n.extend([i for i in range(max(fold_n)+1,n_samples)])\n",
    "        \n",
    "        indices_by_fold[n] = fold_n\n",
    "    \n",
    "    return indices_by_fold\n",
    "\n",
    "\n",
    "def get_train_val_fold_split(indices_by_fold, current_fold):\n",
    "    \"\"\"\n",
    "    Description\n",
    "    -----------\n",
    "    For the current_fold, creates an array of training indices and an array of validation indices.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    indices_by_fold : dict\n",
    "        dict returned from get_fold_indices.\n",
    "    current_fold : int\n",
    "        zero-based fold number in range of cross-validation folds.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    i_train : list\n",
    "        indices of images to be used in the training set (n-1 fold indices).\n",
    "    i_val : list\n",
    "        indices of images to be used in the validation set (1 fold indices).\n",
    "    \"\"\"\n",
    "    i_train = []\n",
    "    i_val = []\n",
    "    for k in indices_by_fold.keys():\n",
    "        if k == current_fold:\n",
    "            i_val.extend(indices_by_fold[k])\n",
    "        else:\n",
    "            i_train.extend(indices_by_fold[k])\n",
    "    return i_train, i_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7577130",
   "metadata": {},
   "source": [
    "### Model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7080d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_class_unet_model(n_classes=4, IMG_HEIGHT=256, IMG_WIDTH=256, IMG_CHANNELS=1):\n",
    "    #Build the model\n",
    "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    s = inputs\n",
    "\n",
    "    #Contraction path\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
    "    c1 = Dropout(0.1)(c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = Dropout(0.1)(c2)\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "     \n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "     \n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    c4 = Dropout(0.2)(c4)\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "     \n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    c5 = Dropout(0.3)(c5)\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "    \n",
    "    #Expansive path \n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "     \n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "     \n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = Dropout(0.1)(c8)\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "     \n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = Dropout(0.1)(c9)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "    \n",
    "    #Multi-class activation\n",
    "    outputs = Conv2D(n_classes, (1, 1), activation='softmax')(c9)\n",
    "    \n",
    "    #Create model\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f83353",
   "metadata": {},
   "source": [
    "### Custom Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97131df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSaver_BatchSizeStudy(Callback):\n",
    "    def __init__(self, study_folder, epochs_list, batch_size, fold):\n",
    "        self.study_folder = study_folder\n",
    "        self.epochs_list = epochs_list\n",
    "        self.batch_size = batch_size\n",
    "        self.fold = fold\n",
    "        super().__init__()\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch in epochs:  # or save after some epoch, each k-th epoch etc.\n",
    "            self.model.save(self.study_folder + \"models/model_bs_{}_f_{}_e_{}.keras\".format(self.batch_size, self.fold, self.epochs_list[self.epochs_list.index(epoch)]))\n",
    "            print(\"model saved ...\")\n",
    "\n",
    "class CustomSaver_LearningRateStudy(Callback):\n",
    "    def __init__(self, study_folder, epochs_list, learning_rate, fold):\n",
    "        self.study_folder = study_folder\n",
    "        self.epochs_list = epochs_list\n",
    "        self.learning_rate = learning_rate\n",
    "        self.fold = fold\n",
    "        super().__init__()\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch in epochs:  # or save after some epoch, each k-th epoch etc.\n",
    "            self.model.save(self.study_folder + \"models/model_l_{}_f_{}_e_{}.keras\".format(str(self.learning_rate).split('.')[1], self.fold, self.epochs_list[self.epochs_list.index(epoch)]))\n",
    "            print(\"model saved ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ed30a8",
   "metadata": {},
   "source": [
    "### Common Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d5980f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross-validation\n",
    "folds = 3\n",
    "\n",
    "#image size\n",
    "SIZE_X = 512\n",
    "SIZE_Y = 512\n",
    "\n",
    "#filepaths\n",
    "image_folder = \"../data/Master/src/\"\n",
    "image_extension = \".jpeg\"\n",
    "\n",
    "mask_folder = \"../data/Master/gt/\"\n",
    "mask_extension = \".bmp\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb6390c",
   "metadata": {},
   "source": [
    "### Batch Size and Epoch Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84ddc634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels in the dataset are ...  [0 1 2 3 4 5 6 7]\n",
      "Number of classes in the dataset is ...  8\n",
      "Class weights dictionary looks like ...: {0: 0.36735640506122164, 1: 4.171348015131236, 2: 1.1228593437742438, 3: 0.45889725780832913, 4: 2.0337580794243313, 5: 17.164363482076368, 6: 0.7339905890630258, 7: 17.85055714896619}\n"
     ]
    }
   ],
   "source": [
    "batch_size = [8, 16, 32, 64]\n",
    "epochs = [10, 50, 100]  #continuously runs to largest epoch in array, but saves model at each epoch in array\n",
    "study_folder = '../batch_size_epoch_study/'\n",
    "\n",
    "#create directories\n",
    "study_dir = os.path.dirname(study_folder)\n",
    "if not os.path.isdir(study_dir):\n",
    "    os.makedirs(study_dir)\n",
    "    os.makedirs(study_dir+'/logs/')\n",
    "    os.makedirs(study_dir+'/models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c84a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "image_input, mask_input, n_classes, class_weights_dict = load_image_and_mask_data(image_folder, image_extension,\n",
    "                                                                                  mask_folder, mask_extension,\n",
    "                                                                                  (SIZE_Y, SIZE_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0f2aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate and compile model\n",
    "model = multi_class_unet_model(n_classes=n_classes, IMG_HEIGHT=SIZE_Y, IMG_WIDTH=SIZE_X, IMG_CHANNELS=1)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980b28bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get cross-validation indices dictionary\n",
    "indices_by_fold = get_fold_indices(X_train.shape[0], folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dafb367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model\n",
    "for b in batch_size:\n",
    "    for f in range(folds):\n",
    "        print(f\"Training model with batch size: {b}, fold: {f}\")\n",
    "        #get cross-validation indices\n",
    "        i_train, i_val = get_train_val_fold_split(indices_by_fold, f)\n",
    "\n",
    "        #callbacks\n",
    "        csv_logger = CSVLogger(study_folder + f'logs/B{b}_F{f}.log', separator=',', append=False)\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, start_from_epoch=10)\n",
    "        saver = CustomSaver_BatchSizeStudy(study_folder, epochs, b, f)\n",
    "\n",
    "        #train\n",
    "        history = model.fit(image_input[i_train], mask_input[i_train],\n",
    "                            batch_size=b,\n",
    "                            verbose=2,\n",
    "                            epochs=e,\n",
    "                            validation_data=(image_input[i_val], mask_input[i_val]),\n",
    "                            class_weight=class_weights_dict,\n",
    "                            shuffle=False,\n",
    "                            callbacks=[csv_logger, early_stopping, saver])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897a64fe",
   "metadata": {},
   "source": [
    "### Learning Rate Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e008b70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.0005, 0.001, 0.01, 0.1, 0.2, 0.3]  #default learning rate is 0.001\n",
    "study_folder = '../learning_rate_study/'\n",
    "\n",
    "#create directories\n",
    "study_dir = os.path.dirname(study_folder)\n",
    "if not os.path.isdir(study_dir):\n",
    "    os.makedirs(study_dir)\n",
    "    os.makedirs(study_dir+'/logs/')\n",
    "    os.makedirs(study_dir+'/models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26c4315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model\n",
    "for l in learning_rates:\n",
    "    #instantiate and compile model with modified optimizer\n",
    "    model = multi_class_unet_model(n_classes=n_classes, IMG_HEIGHT=SIZE_Y, IMG_WIDTH=SIZE_X, IMG_CHANNELS=1)\n",
    "    opt = Adam(learning_rate=l)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    for f in range(folds)\n",
    "        print(f\"Training model with learning rate: {l}, fold: {f}\")\n",
    "        #get cross-validation indices\n",
    "        i_train, i_val = get_train_val_fold_split(indices_by_fold, f)\n",
    "        \n",
    "        #callbacks\n",
    "        csv_logger = CSVLogger(study_folder + f\"logs/L{str(l).split('.')[1]}_F{f}.log\", separator=',', append=False)\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, start_from_epoch=10)\n",
    "        saver = CustomSaver_LearningRateStudy(study_folder epochs, l, f)\n",
    "\n",
    "        #train\n",
    "        history = model.fit(image_input[i_train], mask_input[i_train],\n",
    "                            batch_size=8,\n",
    "                            verbose=2,\n",
    "                            epochs=50,\n",
    "                            validation_data=(image_input[i_val], mask_input[i_val]),\n",
    "                            class_weight=class_weights_dict,\n",
    "                            shuffle=False,\n",
    "                            callbacks=[csv_logger, early_stopping, saver])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33c8df7",
   "metadata": {},
   "source": [
    "### Review Batch Size and Epoch Study Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9169efd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b189741",
   "metadata": {},
   "source": [
    "### Review Learning Rate Study Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59321386",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
